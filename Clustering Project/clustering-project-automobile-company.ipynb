{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "151467a1",
   "metadata": {
    "papermill": {
     "duration": 0.004908,
     "end_time": "2023-06-02T02:58:14.758109",
     "exception": false,
     "start_time": "2023-06-02T02:58:14.753201",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Customer Segmentation Analysis using Clustering\n",
    "\n",
    "### 1.Introduction\n",
    "\n",
    "In the rapidly evolving marketplace, understanding your customer has never been more important. Traditional demographic methods of segmenting customers, such as age or location, can be enhanced with clustering techniques to understand customer behavior and preferences on a much deeper level.\n",
    "\n",
    "In this project, we will apply unsupervised learning techniques to identify segments of the customer population. Clustering is a Machine Learning technique that involves the grouping of data points. Given a set of data points, we can use a clustering algorithm to classify each data point into a specific group.\n",
    "\n",
    "The goal of this project is to segment customers into different groups based on their behavior. The customer behavior can be related to many factors such as gender, age, marital status, spending score, etc. Understanding the distinct groups in our customer base will help in strategizing the marketing activities more effectively.\n",
    "\n",
    "The dataset we will use contains various customer details like gender, marital status, age, graduation details, profession, work experience, spending score, family size and more.\n",
    "\n",
    "We will start with an exploratory data analysis, followed by data preprocessing. Then, we will proceed to find the optimal number of clusters in our data using the Elbow Method and finally apply a KMeans clustering algorithm. The final part of the project will be to analyze and visualize these customer segments. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8deda",
   "metadata": {
    "papermill": {
     "duration": 0.004033,
     "end_time": "2023-06-02T02:58:14.766662",
     "exception": false,
     "start_time": "2023-06-02T02:58:14.762629",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 2. Importing Data and Necessary Libraries\n",
    "\n",
    "In this step, we're importing all the necessary libraries we'll need to analyze the data and perform customer segmentation.\n",
    "\n",
    "The primary libraries we are using are:\n",
    "\n",
    "NumPy: It provides a high-performance multidimensional array object and tools for working with these arrays. It is fundamental for scientific computing with Python.\n",
    "\n",
    "Pandas: This library is excellent for data manipulation and analysis. It provides data structures and functions needed to manipulate structured data.\n",
    "\n",
    "Matplotlib and Seaborn: These are fantastic libraries for data visualization. They provide a flexible interface for creating plots and graphs.\n",
    "\n",
    "Scikit-learn: It's the most widely used machine learning library in Python. We use it for preprocessing the data and also for implementing KMeans clustering.\n",
    "\n",
    "The dataset is loaded into a pandas dataframe, and we display the first few records using the head() function. This gives us an idea of the structure of the dataset we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b0d891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:58:14.777369Z",
     "iopub.status.busy": "2023-06-02T02:58:14.776508Z",
     "iopub.status.idle": "2023-06-02T02:58:17.161322Z",
     "shell.execute_reply": "2023-06-02T02:58:17.160153Z"
    },
    "papermill": {
     "duration": 2.393315,
     "end_time": "2023-06-02T02:58:17.164187",
     "exception": false,
     "start_time": "2023-06-02T02:58:14.770872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/kaggle/input/customer-segmentation/Train.csv')\n",
    "\n",
    "# Display the first few records of our dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53a2582",
   "metadata": {
    "papermill": {
     "duration": 0.004701,
     "end_time": "2023-06-02T02:58:17.173803",
     "exception": false,
     "start_time": "2023-06-02T02:58:17.169102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory Data Analysis (EDA) is the initial step in data analysis, where we uncover the underlying structure of data, extract important parameters and relationships that hold between them. Let's start:\n",
    "\n",
    "Shape of the data: We print the number of rows and columns in the dataset to understand the size of the data we're working with.\n",
    "\n",
    "Missing Values: Here we check if there are any missing values in our dataset across different columns. Missing data can lead to weak or biased analysis.\n",
    "\n",
    "Data Types: Knowing the type of the data is important as the type of data determines the statistical method used to analyze it.\n",
    "\n",
    "Unique Values: We check for unique values in each column to get a sense of the diversity and spread of data.\n",
    "\n",
    "Summary Statistics: We print the summary statistics (count, mean, standard deviation, min, 25 percentile, 50 percentile, 75 percentile, max) of numerical columns to get an understanding of the distribution of different columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa6298e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:58:17.184949Z",
     "iopub.status.busy": "2023-06-02T02:58:17.184550Z",
     "iopub.status.idle": "2023-06-02T02:58:17.250401Z",
     "shell.execute_reply": "2023-06-02T02:58:17.248485Z"
    },
    "papermill": {
     "duration": 0.074178,
     "end_time": "2023-06-02T02:58:17.252748",
     "exception": false,
     "start_time": "2023-06-02T02:58:17.178570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 8068\n",
      "Number of columns in the dataset: 11\n",
      "\n",
      "Missing Values in the dataset:\n",
      " ID                   0\n",
      "Gender               0\n",
      "Ever_Married       140\n",
      "Age                  0\n",
      "Graduated           78\n",
      "Profession         124\n",
      "Work_Experience    829\n",
      "Spending_Score       0\n",
      "Family_Size        335\n",
      "Var_1               76\n",
      "Segmentation         0\n",
      "dtype: int64\n",
      "\n",
      "Data types of the columns:\n",
      " ID                   int64\n",
      "Gender              object\n",
      "Ever_Married        object\n",
      "Age                  int64\n",
      "Graduated           object\n",
      "Profession          object\n",
      "Work_Experience    float64\n",
      "Spending_Score      object\n",
      "Family_Size        float64\n",
      "Var_1               object\n",
      "Segmentation        object\n",
      "dtype: object\n",
      "\n",
      "Unique values in column ID : 8068\n",
      "\n",
      "Unique values in column Gender : 2\n",
      "\n",
      "Unique values in column Ever_Married : 2\n",
      "\n",
      "Unique values in column Age : 67\n",
      "\n",
      "Unique values in column Graduated : 2\n",
      "\n",
      "Unique values in column Profession : 9\n",
      "\n",
      "Unique values in column Work_Experience : 15\n",
      "\n",
      "Unique values in column Spending_Score : 3\n",
      "\n",
      "Unique values in column Family_Size : 9\n",
      "\n",
      "Unique values in column Var_1 : 7\n",
      "\n",
      "Unique values in column Segmentation : 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Family_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8068.000000</td>\n",
       "      <td>8068.000000</td>\n",
       "      <td>7239.000000</td>\n",
       "      <td>7733.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>463479.214551</td>\n",
       "      <td>43.466906</td>\n",
       "      <td>2.641663</td>\n",
       "      <td>2.850123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2595.381232</td>\n",
       "      <td>16.711696</td>\n",
       "      <td>3.406763</td>\n",
       "      <td>1.531413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>458982.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>461240.750000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>463472.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>465744.250000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>467974.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID          Age  Work_Experience  Family_Size\n",
       "count    8068.000000  8068.000000      7239.000000  7733.000000\n",
       "mean   463479.214551    43.466906         2.641663     2.850123\n",
       "std      2595.381232    16.711696         3.406763     1.531413\n",
       "min    458982.000000    18.000000         0.000000     1.000000\n",
       "25%    461240.750000    30.000000         0.000000     2.000000\n",
       "50%    463472.500000    40.000000         1.000000     3.000000\n",
       "75%    465744.250000    53.000000         4.000000     4.000000\n",
       "max    467974.000000    89.000000        14.000000     9.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the data\n",
    "print(\"Number of rows in the dataset:\",df.shape[0])\n",
    "print(\"Number of columns in the dataset:\",df.shape[1])\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"\\nMissing Values in the dataset:\\n\",df.isnull().sum())\n",
    "\n",
    "# Checking the data types\n",
    "print(\"\\nData types of the columns:\\n\",df.dtypes)\n",
    "\n",
    "# Checking the unique values in each column\n",
    "for col in df.columns:\n",
    "    print(\"\\nUnique values in column\", col, \":\",df[col].nunique())\n",
    "\n",
    "# Getting the summary statistics of numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d4304",
   "metadata": {
    "papermill": {
     "duration": 0.004916,
     "end_time": "2023-06-02T02:58:17.262869",
     "exception": false,
     "start_time": "2023-06-02T02:58:17.257953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4. Data Preprocessing\n",
    "\n",
    "Data Preprocessing is a crucial step in the machine learning pipeline. It involves cleaning and formatting the data before feeding into a machine learning algorithm. For this dataset, our data preprocessing will involve the following steps:\n",
    "\n",
    "Filling Missing Values: We observe from the EDA that 'Ever_Married', 'Graduated', 'Profession', 'Work_Experience', 'Family_Size', and 'Var_1' have missing values. For the categorical variables, we will fill the missing values with the most common class (mode). For the numerical variable 'Work_Experience' and 'Family_Size', we will fill the missing values with the mean.\n",
    "\n",
    "One-Hot Encoding: Machine Learning algorithms require input to be numerical, which requires the categorical data to be converted into a numerical form. We perform one-hot encoding on the categorical variables to convert them into a numerical form.\n",
    "\n",
    "Feature Scaling: Many machine learning algorithms perform better when numerical input variables are scaled to a standard range. This includes algorithms that use a weighted sum of inputs like linear regression, and algorithms that use distance measures like k-nearest neighbors. We standardize features by removing the mean and scaling to unit variance using StandardScaler.\n",
    "\n",
    "Dropping 'Var_1': The 'Var_1' column contains anonymized categorical data. While it may contain valuable information, the categories are not described, and thus it's difficult to interpret and use them meaningfully in our analysis. We decide to drop this column for simplicity.\n",
    "\n",
    "Dropping 'Segmentation': The 'Segmentation' column is actually the output from a previous segmentation exercise. Including this in our clustering could bias our results and make it harder to identify truly distinct clusters within the data. As our goal is to demonstrate an unbiased clustering process, we are dropping this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b657daa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:58:17.275858Z",
     "iopub.status.busy": "2023-06-02T02:58:17.275489Z",
     "iopub.status.idle": "2023-06-02T02:58:17.323123Z",
     "shell.execute_reply": "2023-06-02T02:58:17.321683Z"
    },
    "papermill": {
     "duration": 0.057676,
     "end_time": "2023-06-02T02:58:17.326132",
     "exception": false,
     "start_time": "2023-06-02T02:58:17.268456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "df['Ever_Married'].fillna(df['Ever_Married'].mode()[0], inplace=True)\n",
    "df['Graduated'].fillna(df['Graduated'].mode()[0], inplace=True)\n",
    "df['Profession'].fillna(df['Profession'].mode()[0], inplace=True)\n",
    "df['Work_Experience'].fillna(df['Work_Experience'].mean(), inplace=True)\n",
    "df['Family_Size'].fillna(df['Family_Size'].mean(), inplace=True)\n",
    "\n",
    "# Drop 'Var_1' and 'Segmentation' columns\n",
    "df.drop(['Var_1', 'Segmentation'], axis=1, inplace=True)\n",
    "\n",
    "# Converting categorical variables into dummy/indicator variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Drop the 'ID' column as it is not a feature\n",
    "df.drop(['ID'], axis=1, inplace=True)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "df_scaled = sc.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b8131",
   "metadata": {
    "papermill": {
     "duration": 0.005028,
     "end_time": "2023-06-02T02:58:17.336692",
     "exception": false,
     "start_time": "2023-06-02T02:58:17.331664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5. Clustering Modeling\n",
    "\n",
    "To perform clustering on the preprocessed data, we will use the K-means algorithm. This algorithm aims to partition the data into K clusters, where each data point belongs to the cluster with the nearest mean (centroid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8640f3d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:58:17.349627Z",
     "iopub.status.busy": "2023-06-02T02:58:17.348868Z",
     "iopub.status.idle": "2023-06-02T02:58:18.723168Z",
     "shell.execute_reply": "2023-06-02T02:58:18.721956Z"
    },
    "papermill": {
     "duration": 1.383621,
     "end_time": "2023-06-02T02:58:18.725944",
     "exception": false,
     "start_time": "2023-06-02T02:58:17.342323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the KMeans algorithm\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "\n",
    "# Fit the algorithm to the standardized data\n",
    "kmeans.fit(df_scaled)\n",
    "\n",
    "# Get the cluster labels for each data point\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df['Cluster'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02161d9",
   "metadata": {
    "papermill": {
     "duration": 0.005394,
     "end_time": "2023-06-02T02:58:18.740712",
     "exception": false,
     "start_time": "2023-06-02T02:58:18.735318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6. Cluster Evaluation and Interpretation\n",
    "\n",
    "After clustering the data, it is important to evaluate the clusters and interpret their characteristics. One common approach is to analyze the distribution of features within each cluster and identify the unique characteristics of each cluster. This can provide insights into the different segments or groups of customers in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5739edab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T02:58:18.755448Z",
     "iopub.status.busy": "2023-06-02T02:58:18.754186Z",
     "iopub.status.idle": "2023-06-02T02:58:18.773476Z",
     "shell.execute_reply": "2023-06-02T02:58:18.772310Z"
    },
    "papermill": {
     "duration": 0.028724,
     "end_time": "2023-06-02T02:58:18.776325",
     "exception": false,
     "start_time": "2023-06-02T02:58:18.747601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "\n",
      "Age                         48.584473\n",
      "Work_Experience              2.483769\n",
      "Family_Size                  3.150635\n",
      "Gender_Male                  0.619015\n",
      "Ever_Married_Yes             0.999658\n",
      "Graduated_Yes                0.712038\n",
      "Profession_Doctor            0.071135\n",
      "Profession_Engineer          0.096101\n",
      "Profession_Entertainment     0.125171\n",
      "Profession_Executive         0.192544\n",
      "Profession_Healthcare        0.022230\n",
      "Profession_Homemaker         0.029412\n",
      "Profession_Lawyer            0.000000\n",
      "Profession_Marketing         0.016416\n",
      "Spending_Score_High          0.303352\n",
      "Spending_Score_Low           0.034542\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "Cluster 1:\n",
      "\n",
      "Age                         26.142857\n",
      "Work_Experience              2.503044\n",
      "Family_Size                  3.718820\n",
      "Gender_Male                  0.576893\n",
      "Ever_Married_Yes             0.088993\n",
      "Graduated_Yes                0.339578\n",
      "Profession_Doctor            0.000000\n",
      "Profession_Engineer          0.000000\n",
      "Profession_Entertainment     0.000000\n",
      "Profession_Executive         0.000000\n",
      "Profession_Healthcare        0.989071\n",
      "Profession_Homemaker         0.000000\n",
      "Profession_Lawyer            0.000781\n",
      "Profession_Marketing         0.000000\n",
      "Spending_Score_High          0.003903\n",
      "Spending_Score_Low           0.982045\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "Cluster 2:\n",
      "\n",
      "Age                         39.582665\n",
      "Work_Experience              3.074874\n",
      "Family_Size                  2.402675\n",
      "Gender_Male                  0.478717\n",
      "Ever_Married_Yes             0.358729\n",
      "Graduated_Yes                0.658853\n",
      "Profession_Doctor            0.148057\n",
      "Profession_Engineer          0.128933\n",
      "Profession_Entertainment     0.179827\n",
      "Profession_Executive         0.011104\n",
      "Profession_Healthcare        0.000000\n",
      "Profession_Homemaker         0.049352\n",
      "Profession_Lawyer            0.000308\n",
      "Profession_Marketing         0.075262\n",
      "Spending_Score_High          0.000000\n",
      "Spending_Score_Low           0.999383\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "Cluster 3:\n",
      "\n",
      "Age                         75.384863\n",
      "Work_Experience              1.409433\n",
      "Family_Size                  1.979153\n",
      "Gender_Male                  0.508857\n",
      "Ever_Married_Yes             0.938808\n",
      "Graduated_Yes                0.632850\n",
      "Profession_Doctor            0.000000\n",
      "Profession_Engineer          0.000000\n",
      "Profession_Entertainment     0.000000\n",
      "Profession_Executive         0.000000\n",
      "Profession_Healthcare        0.000000\n",
      "Profession_Homemaker         0.000000\n",
      "Profession_Lawyer            1.000000\n",
      "Profession_Marketing         0.000000\n",
      "Spending_Score_High          0.521739\n",
      "Spending_Score_Low           0.449275\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean values of each feature for each cluster\n",
    "cluster_means = df.groupby('Cluster').mean()\n",
    "\n",
    "# Analyze the characteristics of each cluster\n",
    "for cluster in range(4):\n",
    "    print(f\"Cluster {cluster}:\\n\")\n",
    "    print(cluster_means.loc[cluster])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7c8cd",
   "metadata": {
    "papermill": {
     "duration": 0.005241,
     "end_time": "2023-06-02T02:58:18.787174",
     "exception": false,
     "start_time": "2023-06-02T02:58:18.781933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The next step is to understand each cluster better, so the company or client can make different market strategies for each one:\n",
    "\n",
    "Cluster 0: The customers in this cluster are typically around 48 years old, have 2.5 years of work experience, and 3.2 family members. Most of them are male and married, and about 71% are graduates. They come from various professions but are more likely to be executives. Their spending score is predominantly 'high'. This group can be categorized as '**Married Professionals**'.\n",
    "\n",
    "Cluster 1: This cluster represents the youngest group with an average age of 26. They have a similar work experience to the first cluster, around 2.5 years, and they typically have larger families with an average size of 3.7. Majority of them are males and are not married. Most of them are not graduates and work in healthcare. Their spending score is predominantly 'low'. This group can be categorized as '**Young Healthcare Workers**'.\n",
    "\n",
    "Cluster 2: The customers in this cluster are around 40 years old on average, with slightly higher work experience (3 years), and smaller family sizes (2.4). The gender distribution is slightly skewed towards females, and majority are not married. A significant proportion are graduates and they come from diverse professions. Their spending score is predominantly 'low'. This group can be categorized as '**Independent Professionals**'.\n",
    "\n",
    "Cluster 3: This is the oldest group with an average age of 75. They have the lowest work experience (1.4 years), and the smallest family sizes (2.0). The gender distribution is fairly even, and most of them are married. Around 63% are graduates and all of them work as lawyers. Their spending score is split fairly evenly between 'high' and 'low'. This group can be categorized as '**Independent Lawyers**'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1fcbc",
   "metadata": {
    "papermill": {
     "duration": 0.005197,
     "end_time": "2023-06-02T02:58:18.797816",
     "exception": false,
     "start_time": "2023-06-02T02:58:18.792619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 6. Conclusion\n",
    "\n",
    "In this project, we performed a clustering analysis on a dataset of customer information to identify distinct segments or groups within the customer base. The dataset included variables such as gender, age, marital status, profession, and spending score. Our objective was to gain insights into customer behavior and preferences by clustering similar customers together.\n",
    "\n",
    "We started by conducting exploratory data analysis (EDA) to understand the characteristics and distributions of the variables. We then preprocessed the data by handling missing values, converting categorical variables into numerical form, and scaling the features as necessary.\n",
    "\n",
    "Next, we applied a clustering algorithm (K-means) to identify clusters in the data. The clustering algorithm grouped similar customers together based on their attributes, allowing us to identify distinct segments within the customer base.\n",
    "\n",
    "Additionally, we visualized the clusters to gain a better understanding of their distribution and characteristics. The visualization helped us identify patterns and relationships among the clusters.\n",
    "\n",
    "The identified clusters can provide valuable insights for targeted marketing strategies, personalized recommendations, or customer segmentation. By understanding the preferences and behaviors of different customer segments, businesses can tailor their offerings and communication strategies to better meet the specific needs and preferences of each group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.478444,
   "end_time": "2023-06-02T02:58:19.825354",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-02T02:58:02.346910",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
