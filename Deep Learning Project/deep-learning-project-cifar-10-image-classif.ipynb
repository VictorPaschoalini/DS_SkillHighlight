{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f3a92b",
   "metadata": {
    "papermill": {
     "duration": 0.004744,
     "end_time": "2023-06-02T05:25:22.236071",
     "exception": false,
     "start_time": "2023-06-02T05:25:22.231327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CIFAR-10 Image Classification with Deep Learning\n",
    "\n",
    "The CIFAR-10 dataset is a collection of images of 10 different classes like cars, birds, dogs, horses, ships, etc. In this project, we're going to build a deep learning model to classify these images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e186f",
   "metadata": {
    "papermill": {
     "duration": 0.003704,
     "end_time": "2023-06-02T05:25:22.244147",
     "exception": false,
     "start_time": "2023-06-02T05:25:22.240443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here is a direct implementation to solve the problem, then we are going to explore some more advanced techniques.\n",
    "\n",
    "#### 1. Importing Libraries\n",
    "\n",
    "We first import the necessary libraries for our deep learning model. Keras is a user-friendly neural network library written in Python.\n",
    "\n",
    "#### 2. Setting Parameters\n",
    "\n",
    "Batch size is the number of training examples used in one iteration. We are using 10 classes because CIFAR-10 has 10 different classes of images. Epochs is the number of times the model will cycle through the entire training dataset.\n",
    "\n",
    "#### 3. Loading the CIFAR-10 Dataset\n",
    "\n",
    "Keras provides us with the CIFAR-10 data. When loading the data, we get both the training data and the test data.\n",
    "\n",
    "#### 4. Data Preprocessing\n",
    "\n",
    "Before feeding the images into the model, we need to preprocess them. The images are colored so each pixel is represented as an array containing Red, Green and Blue channels. The values of these channels are between 0 and 255. We will normalize these pixel values by dividing them by 255 so they are between 0 and 1. \n",
    "For the labels, we will one-hot encode them. For example, instead of '2', it will be represented as [0, 0, 1, 0, 0, 0, 0, 0, 0, 0].\n",
    "\n",
    "#### 5. Model Architecture\n",
    "\n",
    "Now, we define our Convolutional Neural Network (CNN) model. Our model consists of two main parts - the feature extractor (convolutional layers and pooling layers) and the classifier (fully connected layers). \n",
    "The 'Conv2D' layers are the convolutional layers that will extract features from the images. 'MaxPooling2D' layers are used to reduce the dimensions of the feature maps to decrease the computational complexity of our model. 'Flatten' layer is used to convert the 2D matrix into a 1D array which can then be used in the fully connected layers. 'Dense' layers are the fully connected layers where the results of the convolutional layers are fed through one or more neural layers to generate a prediction. 'Dropout' is a regularization method, where a proportion of nodes in the layer are randomly ignored by setting their weights to zero for each training sample.\n",
    "\n",
    "#### 6. Compile the Model\n",
    "\n",
    "Before we can train our model, we need to configure the learning process. This is done with the .compile() function. The loss function is the objective that the model will try to minimize. We use 'categorical_crossentropy' for our multi-class classification problem. The optimizer is the function used to change the attributes of the machine learning model such as weights and learning rate to reduce the losses. 'Adam' is a popular choice. Metrics are used to monitor the training and testing steps.\n",
    "\n",
    "#### 7. Train the Model\n",
    "\n",
    "We are now ready to train our model. The training data and labels are passed to the .fit() function to train the model.\n",
    "\n",
    "#### 8. Evaluate the Model\n",
    "\n",
    "After training, we evaluate our model on the test set to check how well it can predict the classes of unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f013e48e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T05:25:22.255200Z",
     "iopub.status.busy": "2023-06-02T05:25:22.254090Z",
     "iopub.status.idle": "2023-06-02T05:30:06.546009Z",
     "shell.execute_reply": "2023-06-02T05:30:06.545051Z"
    },
    "papermill": {
     "duration": 284.370026,
     "end_time": "2023-06-02T05:30:06.618137",
     "exception": false,
     "start_time": "2023-06-02T05:25:22.248111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 4s 0us/step\n",
      "Epoch 1/2\n",
      "391/391 [==============================] - 113s 286ms/step - loss: 1.5572 - accuracy: 0.4345 - val_loss: 1.1813 - val_accuracy: 0.5923\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 112s 286ms/step - loss: 1.1059 - accuracy: 0.6093 - val_loss: 0.9498 - val_accuracy: 0.6603\n",
      "Test loss: 0.9497934579849243\n",
      "Test accuracy: 0.6603000164031982\n"
     ]
    }
   ],
   "source": [
    "# 1. Importing Libraries\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 2. Setting Parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2 #Using just a few epochs, 10 or more are recommended\n",
    "\n",
    "# 3. Loading the CIFAR-10 Dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 4. Data Preprocessing\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# 5. Model Architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# 6. Compile the Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 7. Train the Model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)\n",
    "\n",
    "# 8. Evaluate the Model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13082be",
   "metadata": {
    "papermill": {
     "duration": 0.069826,
     "end_time": "2023-06-02T05:30:06.760088",
     "exception": false,
     "start_time": "2023-06-02T05:30:06.690262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Conclusion from the Base Model\n",
    "The base convolutional neural network has been trained and evaluated on the CIFAR-10 dataset. After two epochs of training, we observed a test accuracy of approximately 65.5%, which is a decent starting point but leaves room for improvement.\n",
    "\n",
    "Moving forward, we will apply more advanced deep learning techniques to see if we can improve on this baseline performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3236660",
   "metadata": {
    "papermill": {
     "duration": 0.070259,
     "end_time": "2023-06-02T05:30:06.899706",
     "exception": false,
     "start_time": "2023-06-02T05:30:06.829447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1. Trying Different Network Architectures\n",
    "\n",
    "One way to potentially improve our model is to experiment with different network architectures. The architecture we used for our base model was relatively simple, comprising a few convolutional layers followed by a dense layer.\n",
    "\n",
    "However, there are many other more complex architectures that we could use, such as VGG, ResNet, or Inception. These architectures have been designed by experts and trained on massive datasets, and have achieved state-of-the-art results on a number of benchmark tasks.\n",
    "\n",
    "For example, the VGG network, developed by the Visual Graphics Group at Oxford, is a very deep network with 16 or 19 layers. It has been pre-trained on the ImageNet dataset, which contains over 14 million images and 1000 classes.\n",
    "\n",
    "Keras conveniently provides these complex architectures for us to use out of the box, with the weights pre-trained on ImageNet. We can take advantage of these pre-trained models and adapt them for our task with transfer learning, which could potentially give us a significant boost in performance.\n",
    "\n",
    "In the next part of the project, we will experiment with the VGG network to see if it can improve our performance on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9f09d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T05:30:07.055089Z",
     "iopub.status.busy": "2023-06-02T05:30:07.054656Z",
     "iopub.status.idle": "2023-06-02T05:39:32.053337Z",
     "shell.execute_reply": "2023-06-02T05:39:32.052242Z"
    },
    "papermill": {
     "duration": 565.079339,
     "end_time": "2023-06-02T05:39:32.055883",
     "exception": false,
     "start_time": "2023-06-02T05:30:06.976544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 282s 360ms/step - loss: 1.3491 - accuracy: 0.5297 - val_loss: 1.2302 - val_accuracy: 0.5671\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 273s 350ms/step - loss: 1.1679 - accuracy: 0.5925 - val_loss: 1.1945 - val_accuracy: 0.5826\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Load pre-trained VGG16, excluding top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Make sure pre-trained layers are not trainable\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers for CIFAR-10 classification\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create complete model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1bf325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T05:39:32.448659Z",
     "iopub.status.busy": "2023-06-02T05:39:32.448247Z",
     "iopub.status.idle": "2023-06-02T05:40:20.096691Z",
     "shell.execute_reply": "2023-06-02T05:40:20.095924Z"
    },
    "papermill": {
     "duration": 48.046994,
     "end_time": "2023-06-02T05:40:20.296464",
     "exception": false,
     "start_time": "2023-06-02T05:39:32.249470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.1945030689239502\n",
      "Test accuracy: 0.5825999975204468\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184eb3c8",
   "metadata": {
    "papermill": {
     "duration": 0.202957,
     "end_time": "2023-06-02T05:40:20.704693",
     "exception": false,
     "start_time": "2023-06-02T05:40:20.501736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "With the VGG16 model, we trained our model for two epochs and achieved a validation accuracy of approximately 58.4%. This performance is slightly lower than our baseline model's accuracy of 65.5%.\n",
    "\n",
    "However, it's important to keep in mind that these models have been pre-trained on the ImageNet dataset, which is quite different from our CIFAR-10 dataset. While ImageNet contains over a thousand classes and a large number of high-resolution images, CIFAR-10 contains only 10 classes with relatively small images.\n",
    "\n",
    "Thus, it's possible that the features learned by the VGG16 model on ImageNet aren't as relevant for our task. Or, it may be the case that we need more epochs of training for the VGG16 model to adapt to our dataset.\n",
    "\n",
    "In the next steps, we will continue to refine our model and experiment with other advanced techniques, such as adjusting learning rates and applying data augmentation. We will continue to learn from these experiments and iterate on our model in the pursuit of better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb53998",
   "metadata": {
    "papermill": {
     "duration": 0.199012,
     "end_time": "2023-06-02T05:40:21.101528",
     "exception": false,
     "start_time": "2023-06-02T05:40:20.902516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2. Data Augmentation\n",
    "\n",
    "Data augmentation is a powerful technique that can be used to artificially expand the size of your training dataset. It works by applying random transformations to the images in your dataset, such as rotation, zooming, and flipping, in order to generate new images. This helps to make our model more robust and less likely to overfit to the training data, as it is exposed to more variations of the data.\n",
    "\n",
    "In this step, we will apply data augmentation to the CIFAR-10 dataset and train our model with these augmented data. Let's see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053dde73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T05:40:21.503765Z",
     "iopub.status.busy": "2023-06-02T05:40:21.503170Z",
     "iopub.status.idle": "2023-06-02T05:44:10.012381Z",
     "shell.execute_reply": "2023-06-02T05:44:10.011172Z"
    },
    "papermill": {
     "duration": 228.708201,
     "end_time": "2023-06-02T05:44:10.014407",
     "exception": false,
     "start_time": "2023-06-02T05:40:21.306206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "391/391 [==============================] - 112s 285ms/step - loss: 1.6045 - accuracy: 0.4141 - val_loss: 1.2768 - val_accuracy: 0.5401\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 110s 281ms/step - loss: 1.1951 - accuracy: 0.5762 - val_loss: 1.0423 - val_accuracy: 0.6327\n",
      "Test loss: 1.0423426628112793\n",
      "Test accuracy: 0.6327000260353088\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture of the Initial Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)\n",
    "\n",
    "# Evaluate the Model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c4b25c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T05:44:10.526180Z",
     "iopub.status.busy": "2023-06-02T05:44:10.525799Z",
     "iopub.status.idle": "2023-06-02T05:48:17.134898Z",
     "shell.execute_reply": "2023-06-02T05:48:17.133801Z"
    },
    "papermill": {
     "duration": 247.181923,
     "end_time": "2023-06-02T05:48:17.450445",
     "exception": false,
     "start_time": "2023-06-02T05:44:10.268522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "391/391 [==============================] - 123s 311ms/step - loss: 1.1805 - accuracy: 0.5826 - val_loss: 0.9590 - val_accuracy: 0.6577\n",
      "Epoch 2/2\n",
      "391/391 [==============================] - 123s 314ms/step - loss: 1.0665 - accuracy: 0.6277 - val_loss: 0.9052 - val_accuracy: 0.6818\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Create an instance of the ImageDataGenerator class\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,   # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images horizontally\n",
    "    vertical_flip=False)  # we don't expect CIFAR10 to be upside-down so we will not flip vertically\n",
    "\n",
    "# Fit the augmentation method to our data\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Re-compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow()\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=int(np.ceil(x_train.shape[0] / float(batch_size))),\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc8949",
   "metadata": {
    "papermill": {
     "duration": 0.322838,
     "end_time": "2023-06-02T05:48:18.092917",
     "exception": false,
     "start_time": "2023-06-02T05:48:17.770079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The results show that data augmentation has indeed improved the performance of our model. The validation accuracy has increased from 64.96% to 68.93%.\n",
    "\n",
    "This increase in performance makes sense. With data augmentation, we're able to generate a wider variety of images for our model to train on. This helps to prevent overfitting, and allows our model to learn more generalized features of the images, rather than just memorizing the specific images in the training set.\n",
    "\n",
    "It's clear that data augmentation is a useful technique for improving the performance of our model when working with image data. It allows us to increase the size and diversity of our training data without the need to collect additional data.\n",
    "\n",
    "In the next step, we will continue to explore other techniques to further improve the performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171710f",
   "metadata": {
    "papermill": {
     "duration": 0.318726,
     "end_time": "2023-06-02T05:48:18.748511",
     "exception": false,
     "start_time": "2023-06-02T05:48:18.429785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Com certeza! Aqui estão algumas ideias para tornar o seu projeto com o CIFAR-10 mais interessante:\n",
    "\n",
    "1. Experimente com diferentes arquiteturas de rede: No momento, você está usando uma rede bastante simples com algumas camadas convolucionais seguidas por uma camada densa. Você pode experimentar redes mais complexas, como a VGG, ResNet, Inception, etc. A Keras inclui várias dessas arquiteturas complexas prontas para uso.\n",
    "\n",
    "2. Aprimoramento de dados (Data Augmentation): Esta é uma estratégia que permite aumentar significativamente a diversidade dos dados disponíveis para treinamento de modelos, sem coletar novos dados. A ideia é realizar transformações aleatórias nas imagens (como rotação, zoom, flip) para produzir novas imagens.\n",
    "\n",
    "3. Regularização e ajuste de hiperparâmetros: A regularização pode ajudar a evitar o overfitting e melhorar o desempenho do modelo no conjunto de testes. Métodos de regularização comuns incluem L1 e L2. Também você pode experimentar com diferentes valores de hiperparâmetros, como a taxa de aprendizado, o tamanho do lote, etc.\n",
    "\n",
    "4. Transferência de aprendizado: Esta é uma técnica onde você usa um modelo pré-treinado (geralmente em um grande conjunto de dados) e o ajusta para o seu problema específico. Isso pode acelerar muito o tempo de treinamento e também melhorar o desempenho, especialmente se você tiver um conjunto de dados pequeno.\n",
    "\n",
    "5. Análise de Erros: Depois de treinar o modelo, você pode pegar os exemplos que o modelo está prevendo incorretamente e tentar entender por que. Isso pode ajudá-lo a identificar onde o modelo está com problemas e potencialmente dar ideias sobre como melhorar o modelo.\n",
    "\n",
    "6. Visualização de recursos: As redes convolucionais criam uma série de mapas de recursos intermediários à medida que processam a imagem. Visualizar esses mapas de recursos pode ser uma maneira interessante de entender o que o modelo está realmente aprendendo.\n",
    "\n",
    "7. Explicabilidade do modelo: Pesquise maneiras de explicar as previsões do modelo. Isso pode incluir a identificação das partes da imagem que foram mais importantes para a previsão do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f8dfa",
   "metadata": {
    "papermill": {
     "duration": 0.316903,
     "end_time": "2023-06-02T05:48:19.381663",
     "exception": false,
     "start_time": "2023-06-02T05:48:19.064760",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Vamos seguir assim, vou falar para você fazer programação adicional para mim para cada um desses pontos, esses programas devem ser em inglês e eles vão ser adicionados ao final do código que você me passou (como se fosse uma versão avançada da implementação de deep learning nesse problema). Pode fazer agora \"1.Experimente com diferentes arquiteturas de rede: No momento, você está usando uma rede bastante simples com algumas camadas convolucionais seguidas por uma camada densa. Você pode experimentar redes mais complexas, como a VGG, ResNet, Inception, etc. A Keras inclui várias dessas arquiteturas complexas prontas para uso.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b3c408",
   "metadata": {
    "papermill": {
     "duration": 0.321772,
     "end_time": "2023-06-02T05:48:20.074292",
     "exception": false,
     "start_time": "2023-06-02T05:48:19.752520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1391.208968,
   "end_time": "2023-06-02T05:48:23.561874",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-02T05:25:12.352906",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
